{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7d1e80-cfdd-40da-bc46-ec2b44db0c7f",
   "metadata": {},
   "source": [
    "## Load HIV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5369fcc-7cef-4e51-bd2c-5f8a3e350e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e749e01-8963-455e-8f86-154a0ad10153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"HIV.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc6c87-00f9-4e90-8503-8552506bc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = df.loc[0,'smiles']\n",
    "print(df.loc[0,'smiles'])\n",
    "print(string[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1518a8-a257-475d-9b4d-5759bfa5b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(\"activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c8ecc-b806-4989-a409-017a3826e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(\"HIV_active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47148457-3ed7-404e-8968-f3cdc2716d74",
   "metadata": {},
   "source": [
    "## Transform into SELFIES representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5850e02-8e28-48ba-9eba-f10edcd1d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69bc41-fad9-473b-89ad-4f3d97ad378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "df_sf = df.copy()\n",
    "len_sf=[]\n",
    "for ind in range(len(df_sf['smiles'])):\n",
    "    try:\n",
    "       df_sf.loc[ind, 'smiles'] = sf.encoder(df_sf.loc[ind, 'smiles'])\n",
    "    except:\n",
    "        pass #sf.encoder error!\n",
    "\n",
    "    len_sf.append(sf.len_selfies(df_sf.loc[ind, 'smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad957c-054e-46fd-9393-6af10dead144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sf.rename({'smiles':'selfies'}, axis='columns', inplace=True)\n",
    "df_sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a4f76f-a92e-4c7c-b7d0-6d1139f05e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_sf = df_sf.loc[0,'selfies']\n",
    "print(df_sf.loc[0,'selfies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dacf0-6af4-416d-a8cc-691774292b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and standard deviation\n",
    "print(np.mean(len_sf))\n",
    "print(np.std(len_sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35b678-0055-4d8f-bbda-b83134eee82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(len_sf, bins=range(min(len_sf), max(len_sf) + 1), alpha=0.75, edgecolor='black')\n",
    "plt.title('Histogram of SELFIES String Lengths')\n",
    "plt.xlabel('Length of SELFIES String')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d66fd-b7e7-4781-8f43-ed755768269e",
   "metadata": {},
   "source": [
    "## Padding, tokenization, and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b83267-6e24-4d2a-a72d-b7b680685ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_selfies(string_sf):\n",
    "    # This regex matches anything inside brackets\n",
    "    selfies_elements = re.findall(r'\\[.*?]', string_sf)\n",
    "    return selfies_elements\n",
    "\n",
    "'''\n",
    "# Example usage:\n",
    "string_sf = df_sf.loc[0, 'selfies']\n",
    "selfies_list = split_selfies(string_sf)\n",
    "print(selfies_list)\n",
    "'''\n",
    "\n",
    "def pad_start_end_token(dataset):\n",
    "    \"\"\"\n",
    "    Pad a list of SMILES with \"SOS\" and \"EOS\" token\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles: list of str\n",
    "        A list containing SMILES strings to pad\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    padded: list of list of str\n",
    "        A list containing padded SMILES strings. Example: [['SOS', 'C', 'EOS'], ...]\n",
    "    \"\"\"\n",
    "    padded = []\n",
    "    for ind in range(len(dataset['selfies'])):\n",
    "        padded.append([\"[SOS]\"] + split_selfies(df_sf.loc[ind, 'selfies']) + [\"[EOS]\"])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2d2ea-3285-419d-8512-4ea020c2b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sf = pad_start_end_token(df_sf)\n",
    "vocab = {element: idx for idx, element in enumerate(np.unique(np.concatenate(padded_sf)))}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace65e4b-cfb7-4e83-8402-518238c8ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_selfies(selfies_list, vocab):\n",
    "    \"\"\"Convert a list of SELFIES elements to a list of indices based on the vocabulary (One-hot encoding).\"\"\"\n",
    "    return [vocab[element] for element in selfies_list if element in vocab]\n",
    "\n",
    "\n",
    "\n",
    "class SelfiesEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SelfiesEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa5c5d-5de2-4850-b5a8-cb33a4e4363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_selfies = [tokenize_selfies(selfies, vocab) for selfies in padded_sf]\n",
    "\n",
    "# Instantiate the embedding layer\n",
    "vocab_size = len(vocab)  # Size of your vocabulary\n",
    "embedding_dim = 64  # The size of each embedding vector, which you can choose\n",
    "selfies_embedding_layer = SelfiesEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Convert a list of tokenized selfies to a tensor and pass it through the embedding layer\n",
    "# Pad the sequences to the same length to create a tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_tokenized_selfies = pad_sequence([torch.tensor(ts) for ts in tokenized_selfies],\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=0)  # assuming 0 is the padding index\n",
    "\n",
    "# Get embeddings for the batch of tokenized SELFIES\n",
    "embedded_selfies = selfies_embedding_layer(padded_tokenized_selfies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8635e8c-63c6-43db-b69b-4830dc00baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tokenized_selfies))\n",
    "print(embedded_selfies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3f9de-e04a-4c43-87e5-e69e1b9c4d80",
   "metadata": {},
   "source": [
    "[41127, 399, 128] indicates: <br>\n",
    "41127: the amount of the dataset <br>\n",
    "399: the largest length of selfies string; after the pad_sequence function, all strings should have the same length which is 399 <br>\n",
    "128: the dimension after the embedding <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa5360-6f66-4caf-a9b6-ea825f292f78",
   "metadata": {},
   "source": [
    "## Transform Selfies to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12863822-bde3-4eef-b1c6-b99ce0660cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph_data_object(tokenized_selfies, embedded_selfies):\n",
    "    \"\"\"\n",
    "    Creates a graph data object for each molecule.\n",
    "    \n",
    "    Parameters:\n",
    "    - tokenized_selfies: List of lists, where each sublist is a sequence of token indices for a molecule.\n",
    "    - embedded_selfies: Tensor containing embedded vectors for each token in the tokenized_selfies.\n",
    "    \n",
    "    Returns:\n",
    "    - List of Data objects, one for each molecule.\n",
    "    \"\"\"\n",
    "    graph_data_list = []\n",
    "    \n",
    "    for i, token_list in enumerate(tokenized_selfies):\n",
    "        # Get node features from embeddings\n",
    "        node_features = embedded_selfies[i]\n",
    "        \n",
    "        # Create edges\n",
    "        # Connects each node to the next, creating a path graph\n",
    "        edge_index = []\n",
    "        for j in range(len(token_list) - 1):\n",
    "            edge_index.append([j, j + 1])\n",
    "            edge_index.append([j + 1, j])  # Adding reverse edge for undirected graph\n",
    "            \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        # Create a graph data object\n",
    "        data = Data(x=node_features, edge_index=edge_index)\n",
    "        graph_data_list.append(data)\n",
    "    \n",
    "    return graph_data_list\n",
    "\n",
    "# Assume embedded_selfies is a padded tensor where each row corresponds to embeddings of a molecule\n",
    "graph_data_list = create_graph_data_object(tokenized_selfies, embedded_selfies)\n",
    "\n",
    "# Print the first graph object\n",
    "print(graph_data_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e0a9f8-7c7d-48f8-a1bf-42f9f2200eb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage: Plot the first graph object\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(graph_data_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     plot_graph(graph_data_list[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def plot_graph(data):\n",
    "    \"\"\"\n",
    "    Plot a graph from a PyTorch Geometric Data object.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: PyTorch Geometric Data object containing edge_index and x (node features).\n",
    "    \"\"\"\n",
    "    # Create a networkx graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    num_edges = edge_index.shape[1]\n",
    "    for i in range(0, num_edges, 2):  # step by 2 to avoid adding edges twice\n",
    "        G.add_edge(edge_index[0][i], edge_index[1][i])\n",
    "\n",
    "    # Draw the graph\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    nx.draw(G, with_labels=True, node_color='skyblue', node_size=700, edge_color='#FF5733', font_size=15, font_weight='bold')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: Plot the first graph object\n",
    "if len(graph_data_list) > 0:\n",
    "    plot_graph(graph_data_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc2f300-1aa5-4ec0-b364-fef10576597a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add activity labels to each graph object\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(graph_data_list):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Assuming df_sf and graph_data_list are aligned\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     data\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([df_sf\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph_data_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Add activity labels to each graph object\n",
    "for i, data in enumerate(graph_data_list):\n",
    "    # Assuming df_sf and graph_data_list are aligned\n",
    "    data.y = torch.tensor([df_sf.loc[i, 'activity']])  # Assuming 'activity' is the column with CI/CA/CM labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6cf5ba-1317-4dfb-867b-4ccafecd0b94",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f26293ba-e57f-49e3-a12c-707434feef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activity\n",
      "CI    1000\n",
      "CM     700\n",
      "CA     300\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 首先根據活性分類進行過濾和抽樣\n",
    "sampled_df = pd.DataFrame()  # 初始化一個空的DataFrame用於儲存抽樣結果\n",
    "\n",
    "# 進行隨機抽樣\n",
    "ci_samples = df_sf[df_sf['activity'] == 'CI'].sample(n=1000, random_state=42)  # 從CI類中隨機選取1000個樣本\n",
    "ca_samples = df_sf[df_sf['activity'] == 'CA'].sample(n=300, random_state=42)   # 從CA類中隨機選取300個樣本\n",
    "cm_samples = df_sf[df_sf['activity'] == 'CM'].sample(n=700, random_state=42)   # 從CM類中隨機選取700個樣本\n",
    "\n",
    "# 合併這些抽樣結果到一個新的DataFrame中\n",
    "sampled_df = pd.concat([ci_samples, ca_samples, cm_samples], ignore_index=True)\n",
    "\n",
    "# 檢查抽樣結果\n",
    "print(sampled_df['activity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab17a5b8-0c8a-4afc-bb01-056ef8ca613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total graphs in the sampled dataset: 2000\n"
     ]
    }
   ],
   "source": [
    "# 過濾出已經創建的圖數據對象，使其只包含抽樣的樣本\n",
    "filtered_graph_data_list = [graph_data_list[i] for i in sampled_df.index]\n",
    "\n",
    "# 現在 filtered_graph_data_list 包含了隨機抽取的樣本的圖結構\n",
    "print(f\"Total graphs in the sampled dataset: {len(filtered_graph_data_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972f2a6-aa70-4e55-911d-ef58b6b8113b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c142",
   "language": "python",
   "name": "c142"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
