{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a7d1e80-cfdd-40da-bc46-ec2b44db0c7f",
   "metadata": {},
   "source": [
    "# Load HIV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5369fcc-7cef-4e51-bd2c-5f8a3e350e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e749e01-8963-455e-8f86-154a0ad10153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=S(=O)(O)CCS(=O)(=O)O</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles activity  HIV_active\n",
       "0  CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)...       CI           0\n",
       "1  C(=Cc1ccccc1)C1=[O+][Cu-3]2([O+]=C(C=Cc3ccccc3...       CI           0\n",
       "2                   CC(=O)N1c2ccccc2Sc2c1ccc1ccccc21       CI           0\n",
       "3    Nc1ccc(C=Cc2ccc(N)cc2S(=O)(=O)O)c(S(=O)(=O)O)c1       CI           0\n",
       "4                             O=S(=O)(O)CCS(=O)(=O)O       CI           0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HIV.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cfc6c87-00f9-4e90-8503-8552506bc5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCC1=[O+][Cu-3]2([O+]=C(CC)C1)[O+]=C(CC)CC(CC)=[O+]2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "string = df.loc[0,'smiles']\n",
    "print(df.loc[0,'smiles'])\n",
    "print(string[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1518a8-a257-475d-9b4d-5759bfa5b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity\n",
       "CI    39684\n",
       "CM     1039\n",
       "CA      404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(\"activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "476c8ecc-b806-4989-a409-017a3826e11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIV_active\n",
       "0    39684\n",
       "1     1443\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts(\"HIV_active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47148457-3ed7-404e-8968-f3cdc2716d74",
   "metadata": {},
   "source": [
    "## Transform into SELFIES representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5850e02-8e28-48ba-9eba-f10edcd1d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f69bc41-fad9-473b-89ad-4f3d97ad378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "df_sf = df.copy()\n",
    "len_sf=[]\n",
    "for ind in range(len(df_sf['smiles'])):\n",
    "    try:\n",
    "       df_sf.loc[ind, 'smiles'] = sf.encoder(df_sf.loc[ind, 'smiles'])\n",
    "    except:\n",
    "        pass #sf.encoder error!\n",
    "\n",
    "    len_sf.append(sf.len_selfies(df_sf.loc[ind, 'smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfad957c-054e-46fd-9393-6af10dead144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selfies</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C][C][C][=O+1][Cu-3][Branch1][#Branch2][O+1][...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[C][=Branch1][#Branch2][=C][C][=C][C][=C][C][=...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[C][C][=Branch1][C][=O][N][C][=C][C][=C][C][=C...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[N][C][=C][C][=C][Branch2][Ring1][=Branch1][C]...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O][=S][=Branch1][C][=O][Branch1][C][O][C][C][...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             selfies activity  HIV_active\n",
       "0  [C][C][C][=O+1][Cu-3][Branch1][#Branch2][O+1][...       CI           0\n",
       "1  [C][=Branch1][#Branch2][=C][C][=C][C][=C][C][=...       CI           0\n",
       "2  [C][C][=Branch1][C][=O][N][C][=C][C][=C][C][=C...       CI           0\n",
       "3  [N][C][=C][C][=C][Branch2][Ring1][=Branch1][C]...       CI           0\n",
       "4  [O][=S][=Branch1][C][=O][Branch1][C][O][C][C][...       CI           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sf.rename({'smiles':'selfies'}, axis='columns', inplace=True)\n",
    "df_sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a4f76f-a92e-4c7c-b7d0-6d1139f05e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C][C][C][=O+1][Cu-3][Branch1][#Branch2][O+1][=C][Branch1][Ring1][C][C][C][Ring1][Branch2][O+1][=C][Branch1][Ring1][C][C][C][C][Branch1][Ring1][C][C][=O+1][Ring1][#C]\n"
     ]
    }
   ],
   "source": [
    "string_sf = df_sf.loc[0,'selfies']\n",
    "print(df_sf.loc[0,'selfies'])\n",
    "#print(string_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2dacf0-6af4-416d-a8cc-691774292b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.75984146667639\n",
      "21.70874260604909\n"
     ]
    }
   ],
   "source": [
    "# Compute mean and standard deviation\n",
    "print(np.mean(len_sf))\n",
    "print(np.std(len_sf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f35b678-0055-4d8f-bbda-b83134eee82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a histogram\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(len_sf, bins=range(min(len_sf), max(len_sf) + 1), alpha=0.75, edgecolor='black')\n",
    "plt.title('Histogram of SELFIES String Lengths')\n",
    "plt.xlabel('Length of SELFIES String')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9feeec-2022-47d8-96bb-ea49f3d4d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the dataframe into three categories\n",
    "df_CI = df_sf[df_sf['activity'] == 'CI']\n",
    "df_CM = df_sf[df_sf['activity'] == 'CM']\n",
    "df_CA = df_sf[df_sf['activity'] == 'CA']\n",
    "\n",
    "# Randomly sample 300 from each category\n",
    "sample_CI = df_CI.sample(n=300, random_state=42)  # replace 1 with your chosen seed for reproducibility\n",
    "sample_CM = df_CM.sample(n=300, random_state=42)\n",
    "sample_CA = df_CA.sample(n=300, random_state=42)\n",
    "\n",
    "# Concatenate the samples back into one DataFrame\n",
    "sampled_sf = pd.concat([sample_CI, sample_CM, sample_CA])\n",
    "\n",
    "# If you want to shuffle the combined DataFrame\n",
    "sampled_sf = sampled_sf.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98dfcc06-05ae-4a2e-a4e1-0c44fb9158ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selfies</th>\n",
       "      <th>activity</th>\n",
       "      <th>HIV_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[C][C][C][C][=C][C][=Branch1][C][=O][O][C][=C]...</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[C][C][=C][C][Branch2][=Branch1][=Branch2][N][...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O][=S][=Branch1][C][=O][Branch1][C][O][C][=C]...</td>\n",
       "      <td>CM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[C][O][C][=Branch1][C][=O][C][C][C][Branch1][O...</td>\n",
       "      <td>CI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[C][C][O][C][=C][C][=Ring1][Branch1][C][=Branc...</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             selfies activity  HIV_active\n",
       "0  [C][C][C][C][=C][C][=Branch1][C][=O][O][C][=C]...       CA           1\n",
       "1  [C][C][=C][C][Branch2][=Branch1][=Branch2][N][...       CI           0\n",
       "2  [O][=S][=Branch1][C][=O][Branch1][C][O][C][=C]...       CM           1\n",
       "3  [C][O][C][=Branch1][C][=O][C][C][C][Branch1][O...       CI           0\n",
       "4  [C][C][O][C][=C][C][=Ring1][Branch1][C][=Branc...       CA           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_sf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d66fd-b7e7-4781-8f43-ed755768269e",
   "metadata": {},
   "source": [
    "## Padding, tokenization, and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b83267-6e24-4d2a-a72d-b7b680685ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_selfies(string_sf):\n",
    "    # This regex matches anything inside brackets\n",
    "    selfies_elements = re.findall(r'\\[.*?]', string_sf)\n",
    "    return selfies_elements\n",
    "\n",
    "'''\n",
    "# Example usage:\n",
    "string_sf = df_sf.loc[0, 'selfies']\n",
    "selfies_list = split_selfies(string_sf)\n",
    "print(selfies_list)\n",
    "'''\n",
    "\n",
    "def pad_start_end_token(dataset):\n",
    "    \"\"\"\n",
    "    Pad a list of SMILES with \"SOS\" and \"EOS\" token\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles: list of str\n",
    "        A list containing SMILES strings to pad\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    padded: list of list of str\n",
    "        A list containing padded SMILES strings. Example: [['SOS', 'C', 'EOS'], ...]\n",
    "    \"\"\"\n",
    "    padded = []\n",
    "    for ind in range(len(dataset['selfies'])):\n",
    "        padded.append([\"[SOS]\"] + split_selfies(df_sf.loc[ind, 'selfies']) + [\"[EOS]\"])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96d2d2ea-3285-419d-8512-4ea020c2b019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[#Branch1]': 0,\n",
       " '[#Branch2]': 1,\n",
       " '[#C]': 2,\n",
       " '[#N]': 3,\n",
       " '[=As]': 4,\n",
       " '[=Branch1]': 5,\n",
       " '[=Branch2]': 6,\n",
       " '[=C]': 7,\n",
       " '[=N+1]': 8,\n",
       " '[=N]': 9,\n",
       " '[=O+1]': 10,\n",
       " '[=O]': 11,\n",
       " '[=P]': 12,\n",
       " '[=Ring1]': 13,\n",
       " '[=Ring2]': 14,\n",
       " '[=S+1]': 15,\n",
       " '[=S]': 16,\n",
       " '[Al]': 17,\n",
       " '[As]': 18,\n",
       " '[B]': 19,\n",
       " '[Br]': 20,\n",
       " '[Branch1]': 21,\n",
       " '[Branch2]': 22,\n",
       " '[C]': 23,\n",
       " '[Cl+3]': 24,\n",
       " '[Cl]': 25,\n",
       " '[Co-4]': 26,\n",
       " '[Cu-3]': 27,\n",
       " '[Cu-5]': 28,\n",
       " '[EOS]': 29,\n",
       " '[F]': 30,\n",
       " '[Fe-2]': 31,\n",
       " '[Fe-3]': 32,\n",
       " '[Fe-4]': 33,\n",
       " '[Hg-1]': 34,\n",
       " '[Hg-2]': 35,\n",
       " '[Hg]': 36,\n",
       " '[I]': 37,\n",
       " '[Li]': 38,\n",
       " '[Mn]': 39,\n",
       " '[N+1]': 40,\n",
       " '[N-1]': 41,\n",
       " '[NH1]': 42,\n",
       " '[N]': 43,\n",
       " '[Ni-2]': 44,\n",
       " '[Ni-4]': 45,\n",
       " '[O+1]': 46,\n",
       " '[O-1]': 47,\n",
       " '[O]': 48,\n",
       " '[PH1]': 49,\n",
       " '[P]': 50,\n",
       " '[Pd-2]': 51,\n",
       " '[Ring1]': 52,\n",
       " '[Ring2]': 53,\n",
       " '[S+1]': 54,\n",
       " '[SOS]': 55,\n",
       " '[S]': 56,\n",
       " '[Sb]': 57,\n",
       " '[Se]': 58,\n",
       " '[SiH1]': 59,\n",
       " '[Si]': 60,\n",
       " '[Sn]': 61,\n",
       " '[V-1]': 62,\n",
       " '[Zn-2]': 63,\n",
       " '[Zr]': 64}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sf = pad_start_end_token(sampled_sf)\n",
    "vocab = {element: idx for idx, element in enumerate(np.unique(np.concatenate(padded_sf)))}\n",
    "vocab\n",
    "#padded_sf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ace65e4b-cfb7-4e83-8402-518238c8ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_selfies(selfies_list, vocab):\n",
    "    \"\"\"Convert a list of SELFIES elements to a list of indices based on the vocabulary (One-hot encoding).\"\"\"\n",
    "    return [vocab[element] for element in selfies_list if element in vocab]\n",
    "\n",
    "\n",
    "\n",
    "class SelfiesEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SelfiesEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03aa5c5d-5de2-4850-b5a8-cb33a4e4363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_selfies = [tokenize_selfies(selfies, vocab) for selfies in padded_sf]\n",
    "\n",
    "# Instantiate the embedding layer\n",
    "vocab_size = len(vocab)  # Size of your vocabulary\n",
    "embedding_dim = 128  # The size of each embedding vector, which you can choose\n",
    "selfies_embedding_layer = SelfiesEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Convert a list of tokenized selfies to a tensor and pass it through the embedding layer\n",
    "# Pad the sequences to the same length to create a tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_tokenized_selfies = pad_sequence([torch.tensor(ts) for ts in tokenized_selfies],\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=0)  # assuming 0 is the padding index\n",
    "\n",
    "# Get embeddings for the batch of tokenized SELFIES\n",
    "embedded_selfies = selfies_embedding_layer(padded_tokenized_selfies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8635e8c-63c6-43db-b69b-4830dc00baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\n",
      "torch.Size([900, 169, 128])\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_selfies))\n",
    "print(embedded_selfies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3f9de-e04a-4c43-87e5-e69e1b9c4d80",
   "metadata": {},
   "source": [
    "[900, 169, 128] indicates: <br>\n",
    "900: the amount of the dataset <br>\n",
    "169: the largest length of selfies string; after the pad_sequence function, all strings should have the same length which is 169 <br>\n",
    "128: the dimension after the embedding <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352533aa-c1e0-4f06-a8d6-bb60058515cc",
   "metadata": {},
   "source": [
    "**input shape: (n_batch, n_seq_how many data in a batch, input_dim_How many class do you have)** <br>\n",
    "**LSTM input: torch.nn.LSTM(self, input_size, hidden_size, num_layers=1, bias=True, batch_first=False, dropout=0.0, bidirectional=False, proj_size=0, device=None, dtype=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa5360-6f66-4caf-a9b6-ea825f292f78",
   "metadata": {},
   "source": [
    "# CNN-LSTM Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d794dd41-b888-4cf8-8abb-bca5de2e58a8",
   "metadata": {},
   "source": [
    "**Reference:** <br>\n",
    "Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks. IEEE Conference Publication | IEEE Xplore, 1 Apr. 2015, ieeexplore.ieee.org/document/7178838/authors#authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbaf938e-4389-4ef1-99a9-2a8511072ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SelfiesDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        # Assuming data is a 3D tensor of shape (batch_size, sequence_length, embedding_dim)\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming that the last dimension is the features/embedding dimension\n",
    "        x = self.data[idx, :-1, :]  # All but the last feature\n",
    "        y = self.data[idx, 1:, :]   # All but the first feature (assuming you're predicting the next feature)\n",
    "        return {'X': x, 'y': y}\n",
    "    \n",
    "data_ini = SelfiesDataset(embedded_selfies) # initialize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b3458a1-8e12-499b-9654-f97e72ce593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length):\n",
    "        super(CNNLSTMEncoder, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.cnn = nn.Conv1d(\n",
    "            in_channels=input_dim, out_channels=cnn_channels, kernel_size=kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=cnn_channels, hidden_size=lstm_hidden_size, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Additional layers to get the mean and log variance\n",
    "        self.mu = nn.Linear(lstm_hidden_size * sequence_length, latent_dims)\n",
    "        self.log_var = nn.Linear(lstm_hidden_size * sequence_length, latent_dims)\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.transpose(1, 2)  # Reshape to (batch_size, input_dim, sequence_length)\n",
    "        cnn_out = self.relu(self.cnn(x))\n",
    "        cnn_out = cnn_out.transpose(1, 2)  # Reshape to (batch_size, sequence_length, cnn_channels)\n",
    "        lstm_out, _ = self.lstm(cnn_out)\n",
    "        print(lstm_out.shape,lstm_out.is_cuda)\n",
    "        \n",
    "        # Flatten the output of LSTM to connect to fully connected layers\n",
    "        lstm_out_flat = lstm_out.contiguous().view(batch_size, -1)\n",
    "        print(\"lstm_out_flat size:\", lstm_out_flat.size())  # Debug print statement\n",
    "        mu = self.mu(lstm_out_flat).to(device)\n",
    "        log_var = self.log_var(lstm_out_flat).to(device)\n",
    "        return mu, log_var\n",
    "\n",
    "class CNNLSTMDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length):\n",
    "        super(CNNLSTMDecoder, self).__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_hidden_size, hidden_size=lstm_hidden_size, batch_first=True\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.cnn = nn.ConvTranspose1d(\n",
    "            in_channels=lstm_hidden_size, out_channels=input_dim, kernel_size=kernel_size, padding=kernel_size // 2\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        lstm_out = lstm_out.transpose(1, 2)  # Reshape to (batch_size, lstm_hidden_size, sequence_length)\n",
    "        cnn_out = self.relu(self.cnn(lstm_out))\n",
    "        cnn_out = cnn_out.transpose(1, 2)  # Reshape to (batch_size, sequence_length, input_dim)\n",
    "        print(cnn_out.shape, cnn_out.is_cuda)\n",
    "        return cnn_out\n",
    "\n",
    "class CNNLSTMVAE(nn.Module):\n",
    "    def __init__(self, input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length, latent_dims):\n",
    "        super(CNNLSTMVAE, self).__init__()\n",
    "        self.encoder = CNNLSTMEncoder(\n",
    "            input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length\n",
    "        )\n",
    "        self.decoder = CNNLSTMDecoder(\n",
    "            input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length\n",
    "        )\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.encoder = self.encoder.to(device)\n",
    "        self.decoder = self.decoder.to(device)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        self.latent_dims = latent_dims\n",
    "        \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var).to(device)\n",
    "        eps = torch.randn_like(std).to(device)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)\n",
    "        print(f\"Encoder is completed\",mu.is_cuda, log_var.is_cuda)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        # The decoder will remain the same, but now it takes 'z' as input\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9ece943-9197-4280-8318-ece364285f59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "input_dim: Match the embedding dimension\n",
    "cnn_channels: Number of CNN channels\n",
    "kernel_size: Kernel size for the CNN\n",
    "lstm_hidden_size: Hidden size for the LSTM\n",
    "sequence_length: The length of the padded sequences\n",
    "'''\n",
    "\n",
    "input_dim = 128 \n",
    "cnn_channels = 16\n",
    "kernel_size = 5  \n",
    "lstm_hidden_size = 256  \n",
    "sequence_length = 169\n",
    "num_epochs = 30\n",
    "learning_rate=1e-3\n",
    "l2=1e-3\n",
    "latent_dims=256\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNLSTMVAE(\n",
    "    input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length, latent_dims\n",
    ").to(device)\n",
    "\n",
    "latent_dims = 128  # Dimensionality of the latent representation\n",
    "CLvae = CNNLSTMVAE(input_dim, cnn_channels, kernel_size, lstm_hidden_size, sequence_length, latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d7b8ad-7d83-4ada-93cb-ef0404d1a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def loss_func(outputs, targets, log_var):\n",
    "    reconstruction_loss = F.binary_cross_entropy_with_logits(outputs, targets, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    loss = reconstruction_loss + kl_divergence\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb069797-f250-4e51-bb24-dc61dcf88d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n",
      "torch.Size([32, 168, 256]) True\n",
      "lstm_out_flat size: torch.Size([32, 43008])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x43008 and 43264x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()    \u001b[38;5;66;03m# Zero out any gradients from previous pass\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m recon, mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(recon\u001b[38;5;241m.\u001b[39mis_cuda, mu\u001b[38;5;241m.\u001b[39mis_cuda,log_var\u001b[38;5;241m.\u001b[39mis_cuda)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 79\u001b[0m, in \u001b[0;36mCNNLSTMVAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 79\u001b[0m     mu, log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder is completed\u001b[39m\u001b[38;5;124m\"\u001b[39m,mu\u001b[38;5;241m.\u001b[39mis_cuda, log_var\u001b[38;5;241m.\u001b[39mis_cuda)\n\u001b[0;32m     81\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, log_var)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 31\u001b[0m, in \u001b[0;36mCNNLSTMEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m lstm_out_flat \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_out_flat size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lstm_out_flat\u001b[38;5;241m.\u001b[39msize())  \u001b[38;5;66;03m# Debug print statement\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_out_flat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     32\u001b[0m log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_var(lstm_out_flat)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mu, log_var\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\C242\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x43008 and 43264x128)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Assuming you have a dataset 'dataset' which is a PyTorch Dataset\n",
    "train_loader = DataLoader(data_ini, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = CLvae\n",
    "\n",
    "# Move model to GPU if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Number of epochs to train for\n",
    "model.train()    # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    overall_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # Get the input data and targets\n",
    "        inputs = batch['X']\n",
    "        targets = batch['y']  # For an autoencoder, this is typically the same as inputs\n",
    "        \n",
    "        # Move data to GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        \n",
    "        print(next(model.parameters()).is_cuda, inputs.is_cuda, targets.is_cuda)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()    # Zero out any gradients from previous pass\n",
    "        recon, mu, log_var = model(inputs)\n",
    "\n",
    "        print(recon.is_cuda, mu.is_cuda,log_var.is_cuda)\n",
    "        \n",
    "        # Compute losses\n",
    "        recon_loss = F.mse_loss(recon, inputs, reduction='sum')\n",
    "        kl_div = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        loss = recon_loss + kl_div\n",
    "        loss = loss.to(device)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Loss {loss.item()}')\n",
    "            \n",
    "    print(f'Epoch {epoch}, Average Loss {overall_loss / len(dataloader.dataset)}')\n",
    "\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211ed8d-7af0-434a-a602-a44bfd65b391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca2c8767-e95c-43de-9b04-ab4a1c89e218",
   "metadata": {},
   "source": [
    "# GNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba426f82-c1bb-401a-bd67-c665a1a3cfd7",
   "metadata": {},
   "source": [
    "## Reload the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4defb190-1e1b-41e4-9e9d-9481de2cbf19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[#Branch1]': 0,\n",
       " '[#Branch2]': 1,\n",
       " '[#C-1]': 2,\n",
       " '[#C]': 3,\n",
       " '[#N+1]': 4,\n",
       " '[#N]': 5,\n",
       " '[#O+1]': 6,\n",
       " '[=As]': 7,\n",
       " '[=B-1]': 8,\n",
       " '[=Branch1]': 9,\n",
       " '[=Branch2]': 10,\n",
       " '[=Branch3]': 11,\n",
       " '[=C-1]': 12,\n",
       " '[=C]': 13,\n",
       " '[=Fe]': 14,\n",
       " '[=N+1]': 15,\n",
       " '[=N-1]': 16,\n",
       " '[=NH1+1]': 17,\n",
       " '[=NH2+1]': 18,\n",
       " '[=N]': 19,\n",
       " '[=O+1]': 20,\n",
       " '[=OH1+1]': 21,\n",
       " '[=O]': 22,\n",
       " '[=PH1]': 23,\n",
       " '[=P]': 24,\n",
       " '[=Pd-3]': 25,\n",
       " '[=Re+1]': 26,\n",
       " '[=Ring1]': 27,\n",
       " '[=Ring2]': 28,\n",
       " '[=S+1]': 29,\n",
       " '[=S]': 30,\n",
       " '[=Sb]': 31,\n",
       " '[=Se]': 32,\n",
       " '[=W]': 33,\n",
       " '[Ac]': 34,\n",
       " '[Ag-1]': 35,\n",
       " '[Ag]': 36,\n",
       " '[AlH3-1]': 37,\n",
       " '[AlH3-3]': 38,\n",
       " '[Al]': 39,\n",
       " '[As+1]': 40,\n",
       " '[AsH1]': 41,\n",
       " '[As]': 42,\n",
       " '[Au-1]': 43,\n",
       " '[Au-3]': 44,\n",
       " '[Au]': 45,\n",
       " '[B+1]': 46,\n",
       " '[B+2]': 47,\n",
       " '[B-1]': 48,\n",
       " '[B-2]': 49,\n",
       " '[BH2-1]': 50,\n",
       " '[BH3-1]': 51,\n",
       " '[B]': 52,\n",
       " '[Bi+1]': 53,\n",
       " '[Bi]': 54,\n",
       " '[Br-1]': 55,\n",
       " '[BrH1+1]': 56,\n",
       " '[BrH2+1]': 57,\n",
       " '[Br]': 58,\n",
       " '[Branch1]': 59,\n",
       " '[Branch2]': 60,\n",
       " '[Branch3]': 61,\n",
       " '[C+1]': 62,\n",
       " '[C+]': 63,\n",
       " '[C-1]': 64,\n",
       " '[C-]': 65,\n",
       " '[CH+]': 66,\n",
       " '[CH-]': 67,\n",
       " '[CH1-1]': 68,\n",
       " '[CH2-1]': 69,\n",
       " '[C]': 70,\n",
       " '[Ca-2]': 71,\n",
       " '[Ca-4]': 72,\n",
       " '[CaH2]': 73,\n",
       " '[Cl+3]': 74,\n",
       " '[Cl-1]': 75,\n",
       " '[ClH1+1]': 76,\n",
       " '[ClH2+1]': 77,\n",
       " '[Cl]': 78,\n",
       " '[Co+2]': 79,\n",
       " '[Co-2]': 80,\n",
       " '[Co-3]': 81,\n",
       " '[Co-4]': 82,\n",
       " '[Co]': 83,\n",
       " '[Cr]': 84,\n",
       " '[Cs+1]': 85,\n",
       " '[Cu+2]': 86,\n",
       " '[Cu-1]': 87,\n",
       " '[Cu-2]': 88,\n",
       " '[Cu-3]': 89,\n",
       " '[Cu-4]': 90,\n",
       " '[Cu-5]': 91,\n",
       " '[Cu]': 92,\n",
       " '[EOS]': 93,\n",
       " '[FH1+1]': 94,\n",
       " '[F]': 95,\n",
       " '[Fe+1]': 96,\n",
       " '[Fe+2]': 97,\n",
       " '[Fe+3]': 98,\n",
       " '[Fe-1]': 99,\n",
       " '[Fe-2]': 100,\n",
       " '[Fe-3]': 101,\n",
       " '[Fe-4]': 102,\n",
       " '[Fe]': 103,\n",
       " '[Ga-1]': 104,\n",
       " '[Ga-3]': 105,\n",
       " '[GaH3]': 106,\n",
       " '[Ga]': 107,\n",
       " '[Gd+3]': 108,\n",
       " '[GeH2+1]': 109,\n",
       " '[Ge]': 110,\n",
       " '[H+1]': 111,\n",
       " '[H-1]': 112,\n",
       " '[H]': 113,\n",
       " '[Hg-1]': 114,\n",
       " '[Hg-2]': 115,\n",
       " '[Hg]': 116,\n",
       " '[Ho]': 117,\n",
       " '[I+1]': 118,\n",
       " '[I-1]': 119,\n",
       " '[I-]': 120,\n",
       " '[IH2+1]': 121,\n",
       " '[IH2]': 122,\n",
       " '[I]': 123,\n",
       " '[Ir+1]': 124,\n",
       " '[Ir+3]': 125,\n",
       " '[Ir-3]': 126,\n",
       " '[Ir-4]': 127,\n",
       " '[K+1]': 128,\n",
       " '[KH1]': 129,\n",
       " '[LiH1]': 130,\n",
       " '[Li]': 131,\n",
       " '[MgH1]': 132,\n",
       " '[MgH2]': 133,\n",
       " '[Mg]': 134,\n",
       " '[Mn+1]': 135,\n",
       " '[Mn+2]': 136,\n",
       " '[Mn+3]': 137,\n",
       " '[Mn]': 138,\n",
       " '[Mo+1]': 139,\n",
       " '[Mo+2]': 140,\n",
       " '[Mo+]': 141,\n",
       " '[Mo-1]': 142,\n",
       " '[Mo-3]': 143,\n",
       " '[Mo]': 144,\n",
       " '[N+1]': 145,\n",
       " '[N+]': 146,\n",
       " '[N-1]': 147,\n",
       " '[N-]': 148,\n",
       " '[NH+]': 149,\n",
       " '[NH1+1]': 150,\n",
       " '[NH1-1]': 151,\n",
       " '[NH1]': 152,\n",
       " '[NH2+1]': 153,\n",
       " '[N]': 154,\n",
       " '[Na+1]': 155,\n",
       " '[NaH1]': 156,\n",
       " '[Na]': 157,\n",
       " '[Ni-2]': 158,\n",
       " '[Ni-3]': 159,\n",
       " '[Ni-4]': 160,\n",
       " '[Ni]': 161,\n",
       " '[O+1]': 162,\n",
       " '[O+]': 163,\n",
       " '[O-1]': 164,\n",
       " '[O-]': 165,\n",
       " '[OH+]': 166,\n",
       " '[OH1+1]': 167,\n",
       " '[OH2+1]': 168,\n",
       " '[O]': 169,\n",
       " '[P+1]': 170,\n",
       " '[P+]': 171,\n",
       " '[P-1]': 172,\n",
       " '[P-]': 173,\n",
       " '[PH-]': 174,\n",
       " '[PH1]': 175,\n",
       " '[PH]': 176,\n",
       " '[P]': 177,\n",
       " '[Pb]': 178,\n",
       " '[Pd+2]': 179,\n",
       " '[Pd-2]': 180,\n",
       " '[Pd-3]': 181,\n",
       " '[Pd-4]': 182,\n",
       " '[Pt+2]': 183,\n",
       " '[Pt-2]': 184,\n",
       " '[Pt-3]': 185,\n",
       " '[Pt-4]': 186,\n",
       " '[Pt]': 187,\n",
       " '[Re+1]': 188,\n",
       " '[Rh+2]': 189,\n",
       " '[Rh-4]': 190,\n",
       " '[Ring1]': 191,\n",
       " '[Ring2]': 192,\n",
       " '[Ru+1]': 193,\n",
       " '[Ru+2]': 194,\n",
       " '[Ru-2]': 195,\n",
       " '[Ru-4]': 196,\n",
       " '[Ru]': 197,\n",
       " '[S+1]': 198,\n",
       " '[S+]': 199,\n",
       " '[S-1]': 200,\n",
       " '[S-2]': 201,\n",
       " '[SH+]': 202,\n",
       " '[SH1+1]': 203,\n",
       " '[SH1]': 204,\n",
       " '[SOS]': 205,\n",
       " '[S]': 206,\n",
       " '[Sb+1]': 207,\n",
       " '[Sb]': 208,\n",
       " '[Se]': 209,\n",
       " '[SiH1-1]': 210,\n",
       " '[SiH1]': 211,\n",
       " '[Si]': 212,\n",
       " '[Sn]': 213,\n",
       " '[Tb]': 214,\n",
       " '[Te]': 215,\n",
       " '[Ti-2]': 216,\n",
       " '[Ti]': 217,\n",
       " '[Tl-1]': 218,\n",
       " '[Tl-3]': 219,\n",
       " '[U+2]': 220,\n",
       " '[U-5]': 221,\n",
       " '[U]': 222,\n",
       " '[V+]': 223,\n",
       " '[V-1]': 224,\n",
       " '[W+2]': 225,\n",
       " '[W]': 226,\n",
       " '[Zn-2]': 227,\n",
       " '[Zn-3]': 228,\n",
       " '[Zn-4]': 229,\n",
       " '[Zn]': 230,\n",
       " '[Zr]': 231}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sf = pad_start_end_token(df_sf)\n",
    "vocab = {element: idx for idx, element in enumerate(np.unique(np.concatenate(padded_sf)))}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c29ea5a-6413-44ac-8ed5-a9d814be06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_selfies = [tokenize_selfies(selfies, vocab) for selfies in padded_sf]\n",
    "\n",
    "# Instantiate the embedding layer\n",
    "vocab_size = len(vocab)  # Size of your vocabulary\n",
    "embedding_dim = 64  # The size of each embedding vector, which you can choose\n",
    "selfies_embedding_layer = SelfiesEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Convert a list of tokenized selfies to a tensor and pass it through the embedding layer\n",
    "# Pad the sequences to the same length to create a tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "padded_tokenized_selfies = pad_sequence([torch.tensor(ts) for ts in tokenized_selfies],\n",
    "                                        batch_first=True,\n",
    "                                        padding_value=0)  # assuming 0 is the padding index\n",
    "\n",
    "# Get embeddings for the batch of tokenized SELFIES\n",
    "embedded_selfies = selfies_embedding_layer(padded_tokenized_selfies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da890fcf-01bc-43db-975e-d4ce55400747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41127\n",
      "torch.Size([41127, 399, 64])\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_selfies))\n",
    "print(embedded_selfies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86db908f-86fb-459b-a7de-d02f85a31def",
   "metadata": {},
   "source": [
    "[41127, 399, 128] indicates: <br>\r\n",
    "41127: the amount of the dataset\r\n",
    "399: the largest length of selfies string; after the pad_sequence function, all strings should have the same length which is 399\r\n",
    "128: the dimension after the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0536b88-184e-436b-8ebc-e22d0a8f48ec",
   "metadata": {},
   "source": [
    "## Transform Selfies to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c300922-03cd-4f5a-90b5-c8fa3c2d2fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[399, 64], edge_index=[2, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def create_graph_data_object(tokenized_selfies, embedded_selfies):\n",
    "    \"\"\"\n",
    "    Creates a graph data object for each molecule.\n",
    "    \n",
    "    Parameters:\n",
    "    - tokenized_selfies: List of lists, where each sublist is a sequence of token indices for a molecule.\n",
    "    - embedded_selfies: Tensor containing embedded vectors for each token in the tokenized_selfies.\n",
    "    \n",
    "    Returns:\n",
    "    - List of Data objects, one for each molecule.\n",
    "    \"\"\"\n",
    "    graph_data_list = []\n",
    "    \n",
    "    for i, token_list in enumerate(tokenized_selfies):\n",
    "        # Get node features from embeddings\n",
    "        node_features = embedded_selfies[i]\n",
    "        \n",
    "        # Create edges\n",
    "        # Connects each node to the next, creating a path graph\n",
    "        edge_index = []\n",
    "        for j in range(len(token_list) - 1):\n",
    "            edge_index.append([j, j + 1])\n",
    "            edge_index.append([j + 1, j])  # Adding reverse edge for undirected graph\n",
    "            \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        \n",
    "        # Create a graph data object\n",
    "        data = Data(x=node_features, edge_index=edge_index)\n",
    "        graph_data_list.append(data)\n",
    "    \n",
    "    return graph_data_list\n",
    "\n",
    "# Assume embedded_selfies is a padded tensor where each row corresponds to embeddings of a molecule\n",
    "graph_data_list = create_graph_data_object(tokenized_selfies, embedded_selfies)\n",
    "\n",
    "# Print the first graph object\n",
    "print(graph_data_list[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859ee599-c09b-4510-b331-508d89773c8d",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a4c597d-a706-4f83-a0fa-e5cc9fe0556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>graph_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41122</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41123</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41124</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41125</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41126</th>\n",
       "      <td>CI</td>\n",
       "      <td>[(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41127 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activity                                         graph_data\n",
       "0           CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "1           CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "2           CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "3           CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "4           CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "...        ...                                                ...\n",
       "41122       CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "41123       CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "41124       CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "41125       CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "41126       CI  [(x, [tensor([-0.6236, -0.1435, -1.6164,  1.07...\n",
       "\n",
       "[41127 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure that your dataframe and your graph data list are aligned\n",
    "df_sf['graph_data'] = graph_data_list\n",
    "\n",
    "# Check that the lengths and indices are correctly aligned\n",
    "assert len(df_sf) == len(graph_data_list), \"Dataframe and graph list length mismatch.\"\n",
    "\n",
    "# Filter out any potential NaNs if something went wrong during graph creation\n",
    "df_sf = df_sf.dropna(subset=['graph_data'])\n",
    "df_gf = df_sf.drop(columns=['selfies','HIV_active'])\n",
    "df_gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "273c2825-2c7b-4338-8a52-521cad93875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling from each category\n",
    "ci_sample = df_gf[df_gf['activity'] == 'CI'].sample(n=1000, random_state=42)\n",
    "ca_sample = df_gf[df_gf['activity'] == 'CA'].sample(n=300, random_state=42)\n",
    "cm_sample = df_gf[df_gf['activity'] == 'CM'].sample(n=700, random_state=42)\n",
    "# Combine the samples\n",
    "graph_df = pd.concat([ci_sample, ca_sample, cm_sample])\n",
    "\n",
    "# Shuffle the combined dataframe to randomize the order of data points\n",
    "graph_df = graph_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Extract the graph data objects for training\n",
    "train_graphs = graph_df['graph_data'].tolist()\n",
    "train_labels = graph_df['activity'].tolist()  # Assuming you want to use string labels directly\n",
    "\n",
    "# If numerical labels are needed, convert them\n",
    "activity_to_index = {'CI': 0, 'CA': 1, 'CM': 2}\n",
    "train_labels = [activity_to_index[label] for label in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38215ad-e1e4-46be-9b57-89d9c520198a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C242",
   "language": "python",
   "name": "c242"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
